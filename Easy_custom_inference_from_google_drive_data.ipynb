{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd5kcEpTK8HIEoWdVoTdHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phytometrics/arabidopsis_leaf_stomata_quantification/blob/main/Easy_custom_inference_from_google_drive_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy code execution version with Google Drive"
      ],
      "metadata": {
        "id": "5mLTWrke5XdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Activation"
      ],
      "metadata": {
        "id": "YFgpZyvA5d4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authorization window popsup. Must finish the procedure to continue the process.\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "metadata": {
        "id": "3Bu4B0AQ5glp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed279d6-6ef3-4a96-e177-906c3f433fc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation (do not unfold this cell block. Press execute button below once.)"
      ],
      "metadata": {
        "id": "-M9eikfOaFPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "8_g5lVlgcoAl",
        "outputId": "019bcd5a-60ee-4423-9b62-b6965389b555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.19.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage.measure import label, regionprops, find_contours\n",
        "import onnxruntime\n",
        "import gdown\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "mHZmHn2xcNu2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get model weights"
      ],
      "metadata": {
        "id": "opq7gB3ZaCA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FpmX6eH0a9vQ",
        "outputId": "7fccdfce-4b20-4c8d-a92c-e8fd4822a971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HjZJzRjs5NXlXchbRqOGybdSXx--HZNF\n",
            "To: /content/221121_micro_yolox_s1920.onnx\n",
            "100% 35.8M/35.8M [00:00<00:00, 85.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hhr68lZsycMmFkQlZ7WphK6cru29oZgN\n",
            "To: /content/221121_micro_seg.onnx\n",
            "100% 26.7M/26.7M [00:00<00:00, 32.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "det = \"1HjZJzRjs5NXlXchbRqOGybdSXx--HZNF\"\n",
        "seg = \"1Hhr68lZsycMmFkQlZ7WphK6cru29oZgN\"\n",
        "!gdown {det}\n",
        "!gdown {seg}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline\n"
      ],
      "metadata": {
        "id": "O8pywCiZaMlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the codes in this cell are adopted/customized based on the following sites. Authors do not claim any rights regarding this code cell\n",
        "# https://github.com/Kazuhito00/YOLOX-ONNX-TFLite-Sample\n",
        "# https://github.com/Megvii-BaseDetection/YOLOX/blob/main/yolox/utils/visualize.py\n",
        "# both of the original repository are licenced with APACHE LICENSE 2.0\n",
        "\n",
        "class YoloxONNX(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path=\"\",\n",
        "        input_shape=(1920, 1920),\n",
        "        nms_th=0.45,\n",
        "        score_th=0.1,\n",
        "        with_p6=False,\n",
        "        providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],\n",
        "    ):\n",
        "        self.input_shape = input_shape\n",
        "        self.model_path = model_path\n",
        "        self.nms_th = nms_th\n",
        "        self.score_th = score_th\n",
        "        self.with_p6 = with_p6\n",
        "        self.onnx_session = onnxruntime.InferenceSession(\n",
        "            self.model_path,\n",
        "            providers=[providers[0]],\n",
        "        )\n",
        "\n",
        "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
        "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
        "\n",
        "    def inference(self, image):\n",
        "        temp_image = copy.deepcopy(image)\n",
        "        image_height, image_width = image.shape[0], image.shape[1]\n",
        "        image, ratio = self._preprocess(temp_image, self.input_shape)\n",
        "        results = self.onnx_session.run(\n",
        "            None,\n",
        "            {self.input_name: image[None, :, :, :]},\n",
        "        )\n",
        "        bboxes, scores, class_ids = self._postprocess(\n",
        "            results[0],\n",
        "            self.input_shape,\n",
        "            ratio,\n",
        "            self.nms_th,\n",
        "            self.score_th,\n",
        "            image_width,\n",
        "            image_height,\n",
        "            p6=self.with_p6,\n",
        "        )\n",
        "\n",
        "        return bboxes, scores, class_ids\n",
        "\n",
        "    def _preprocess(self, image, input_size, swap=(2, 0, 1)):\n",
        "        if len(image.shape) == 3:\n",
        "            padded_image = np.ones(\n",
        "                (input_size[0], input_size[1], 3), dtype=np.uint8) * 114\n",
        "        else:\n",
        "            padded_image = np.ones(input_size, dtype=np.uint8) * 114\n",
        "\n",
        "        ratio = min(input_size[0] / image.shape[0],\n",
        "                    input_size[1] / image.shape[1])\n",
        "        resized_image = cv2.resize(\n",
        "            image,\n",
        "            (int(image.shape[1] * ratio), int(image.shape[0] * ratio)),\n",
        "            interpolation=cv2.INTER_LINEAR,\n",
        "        )\n",
        "        resized_image = resized_image.astype(np.uint8)\n",
        "\n",
        "        padded_image[:int(image.shape[0] * ratio), :int(image.shape[1] *\n",
        "                                                        ratio)] = resized_image\n",
        "        padded_image = padded_image.transpose(swap)\n",
        "        padded_image = np.ascontiguousarray(padded_image, dtype=np.float32)\n",
        "\n",
        "        return padded_image, ratio\n",
        "\n",
        "    def _postprocess(\n",
        "        self,\n",
        "        outputs,\n",
        "        img_size,\n",
        "        ratio,\n",
        "        nms_th,\n",
        "        score_th,\n",
        "        max_width,\n",
        "        max_height,\n",
        "        p6=False,\n",
        "    ):\n",
        "        grids = []\n",
        "        expanded_strides = []\n",
        "\n",
        "        if not p6:\n",
        "            strides = [8, 16, 32]\n",
        "        else:\n",
        "            strides = [8, 16, 32, 64]\n",
        "\n",
        "        hsizes = [img_size[0] // stride for stride in strides]\n",
        "        wsizes = [img_size[1] // stride for stride in strides]\n",
        "\n",
        "        for hsize, wsize, stride in zip(hsizes, wsizes, strides):\n",
        "            xv, yv = np.meshgrid(np.arange(wsize), np.arange(hsize))\n",
        "            grid = np.stack((xv, yv), 2).reshape(1, -1, 2)\n",
        "            grids.append(grid)\n",
        "            shape = grid.shape[:2]\n",
        "            expanded_strides.append(np.full((*shape, 1), stride))\n",
        "\n",
        "        grids = np.concatenate(grids, 1)\n",
        "        expanded_strides = np.concatenate(expanded_strides, 1)\n",
        "        outputs[..., :2] = (outputs[..., :2] + grids) * expanded_strides\n",
        "        outputs[..., 2:4] = np.exp(outputs[..., 2:4]) * expanded_strides\n",
        "\n",
        "        predictions = outputs[0]\n",
        "        boxes = predictions[:, :4]\n",
        "        scores = predictions[:, 4:5] * predictions[:, 5:]\n",
        "\n",
        "        boxes_xyxy = np.ones_like(boxes)\n",
        "        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2.\n",
        "        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2.\n",
        "        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2.\n",
        "        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2.\n",
        "        boxes_xyxy /= ratio\n",
        "\n",
        "        dets = self._multiclass_nms(\n",
        "            boxes_xyxy,\n",
        "            scores,\n",
        "            nms_thr=nms_th,\n",
        "            score_thr=score_th,\n",
        "        )\n",
        "\n",
        "        bboxes, scores, class_ids = [], [], []\n",
        "        if dets is not None:\n",
        "            bboxes, scores, class_ids = dets[:, :4], dets[:, 4], dets[:, 5]\n",
        "            for bbox in bboxes:\n",
        "                bbox[0] = max(0, bbox[0])\n",
        "                bbox[1] = max(0, bbox[1])\n",
        "                bbox[2] = min(bbox[2], max_width)\n",
        "                bbox[3] = min(bbox[3], max_height)\n",
        "\n",
        "        return bboxes, scores, class_ids\n",
        "\n",
        "    def _nms(self, boxes, scores, nms_thr):\n",
        "        x1 = boxes[:, 0]\n",
        "        y1 = boxes[:, 1]\n",
        "        x2 = boxes[:, 2]\n",
        "        y2 = boxes[:, 3]\n",
        "\n",
        "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "        order = scores.argsort()[::-1]\n",
        "\n",
        "        keep = []\n",
        "        while order.size > 0:\n",
        "            i = order[0]\n",
        "            keep.append(i)\n",
        "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "            inter = w * h\n",
        "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "\n",
        "            inds = np.where(ovr <= nms_thr)[0]\n",
        "            order = order[inds + 1]\n",
        "\n",
        "        return keep\n",
        "\n",
        "    def _multiclass_nms(\n",
        "        self,\n",
        "        boxes,\n",
        "        scores,\n",
        "        nms_thr,\n",
        "        score_thr,\n",
        "        class_agnostic=True,\n",
        "    ):\n",
        "        if class_agnostic:\n",
        "            nms_method = self._multiclass_nms_class_agnostic\n",
        "        else:\n",
        "            nms_method = self._multiclass_nms_class_aware\n",
        "\n",
        "        return nms_method(boxes, scores, nms_thr, score_thr)\n",
        "\n",
        "    def _multiclass_nms_class_aware(self, boxes, scores, nms_thr, score_thr):\n",
        "        final_dets = []\n",
        "        num_classes = scores.shape[1]\n",
        "\n",
        "        for cls_ind in range(num_classes):\n",
        "            cls_scores = scores[:, cls_ind]\n",
        "            valid_score_mask = cls_scores > score_thr\n",
        "\n",
        "            if valid_score_mask.sum() == 0:\n",
        "                continue\n",
        "            else:\n",
        "                valid_scores = cls_scores[valid_score_mask]\n",
        "                valid_boxes = boxes[valid_score_mask]\n",
        "                keep = self._nms(valid_boxes, valid_scores, nms_thr)\n",
        "                if len(keep) > 0:\n",
        "                    cls_inds = np.ones((len(keep), 1)) * cls_ind\n",
        "                    dets = np.concatenate(\n",
        "                        [\n",
        "                            valid_boxes[keep], valid_scores[keep, None],\n",
        "                            cls_inds\n",
        "                        ],\n",
        "                        1,\n",
        "                    )\n",
        "                    final_dets.append(dets)\n",
        "\n",
        "        if len(final_dets) == 0:\n",
        "            return None\n",
        "\n",
        "        return np.concatenate(final_dets, 0)\n",
        "\n",
        "    def _multiclass_nms_class_agnostic(self, boxes, scores, nms_thr,\n",
        "                                       score_thr):\n",
        "        cls_inds = scores.argmax(1)\n",
        "        cls_scores = scores[np.arange(len(cls_inds)), cls_inds]\n",
        "\n",
        "        valid_score_mask = cls_scores > score_thr\n",
        "\n",
        "        if valid_score_mask.sum() == 0:\n",
        "            return None\n",
        "\n",
        "        valid_scores = cls_scores[valid_score_mask]\n",
        "        valid_boxes = boxes[valid_score_mask]\n",
        "        valid_cls_inds = cls_inds[valid_score_mask]\n",
        "        keep = self._nms(valid_boxes, valid_scores, nms_thr)\n",
        "\n",
        "        dets = None\n",
        "        if keep:\n",
        "            dets = np.concatenate([\n",
        "                valid_boxes[keep],\n",
        "                valid_scores[keep, None],\n",
        "                valid_cls_inds[keep, None],\n",
        "            ], 1)\n",
        "\n",
        "        return dets\n",
        "def annotate(img, boxes, scores, cls_ids, conf=0.5, class_names=None, text=True, CROP_SIZE=64):\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        cls_id = int(cls_ids[i])\n",
        "        score = scores[i]\n",
        "        if score < conf:\n",
        "            continue\n",
        "        x0 = int(box[0])\n",
        "        y0 = int(box[1])\n",
        "        x1 = int(box[2])\n",
        "        y1 = int(box[3])\n",
        "\n",
        "        xmin, ymin, xmax, ymax = x0, y0, x1, y1\n",
        "        xcenter = int((xmin + xmax) / 2)\n",
        "        ycenter = int((ymin + ymax) / 2)\n",
        "        new_xmin = xcenter - CROP_SIZE // 2\n",
        "        new_ymin = ycenter - CROP_SIZE // 2\n",
        "        new_xmax = xcenter + CROP_SIZE // 2\n",
        "        new_ymax = ycenter + CROP_SIZE // 2\n",
        "        new_xmin = np.max([0, new_xmin]) \n",
        "        new_ymin = np.max([0, new_ymin])\n",
        "        new_xmax = np.min([img.shape[1], new_xmax])\n",
        "        new_ymax = np.min([img.shape[0], new_ymax])\n",
        "\n",
        "        x0, y0, x1, y1 = new_xmin, new_ymin, new_xmax, new_ymax\n",
        "\n",
        "        color = (_COLORS[cls_id] * 255).astype(np.uint8).tolist()\n",
        "        text = '{}:{:.1f}%'.format(class_names[cls_id], score * 100)\n",
        "        txt_color = (0, 0, 0) if np.mean(_COLORS[cls_id]) > 0.5 else (255, 255, 255)\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        txt_size = cv2.getTextSize(text, font, 0.4, 1)[0]\n",
        "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
        "\n",
        "        txt_bk_color = (_COLORS[cls_id] * 255 * 0.7).astype(np.uint8).tolist()\n",
        "        if text:\n",
        "            cv2.rectangle(\n",
        "                img,\n",
        "                (x0, y0 + 1),\n",
        "                (x0 + txt_size[0] + 1, y0 + int(1.5*txt_size[1])),\n",
        "                txt_bk_color,\n",
        "                -1\n",
        "            )\n",
        "            cv2.putText(img, text, (x0, y0 + txt_size[1]), font, 0.4, txt_color, thickness=1)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "_COLORS = np.array(\n",
        "    [\n",
        "        1., 0., 0., # open red\n",
        "        0., 0., 1., # close blue\n",
        "        # R, G, B\n",
        "    ]\n",
        ").astype(np.float32).reshape(-1, 3)"
      ],
      "metadata": {
        "id": "ZQciEEgNcUkV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Segmentation(object):\n",
        "    def __init__(self,\n",
        "                 model_path=\"\",\n",
        "                 input_shape=(64, 64),\n",
        "                 providers=['CPUExecutionProvider'],\n",
        "                 ):\n",
        "        self.input_shape = input_shape\n",
        "        self.onnx_session = onnxruntime.InferenceSession(\n",
        "            model_path,\n",
        "            providers=providers,\n",
        "        )\n",
        "\n",
        "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
        "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
        "\n",
        "    def inference(self, image):\n",
        "        image = image.transpose((2, 0, 1)).astype(\"float32\")\n",
        "        result = self.onnx_session.run(\n",
        "            None,\n",
        "            {self.input_name: image[None, :, :, :]},\n",
        "        )[0][0][0]\n",
        "        return result\n",
        "\n",
        "\n",
        "def crop_stomata(image, dets, CROP_SIZE):\n",
        "    stomatas = []\n",
        "    offsets = []\n",
        "\n",
        "    for det in dets:\n",
        "        xmin, ymin, xmax, ymax = det[0], det[1], det[2], det[3]\n",
        "        xcenter = int((xmin + xmax) / 2)\n",
        "        ycenter = int((ymin + ymax) / 2)\n",
        "        new_xmin = xcenter - CROP_SIZE // 2\n",
        "        new_ymin = ycenter - CROP_SIZE // 2\n",
        "        new_xmax = xcenter + CROP_SIZE // 2\n",
        "        new_ymax = ycenter + CROP_SIZE // 2\n",
        "        new_xmin = np.max([0, new_xmin])\n",
        "        new_ymin = np.max([0, new_ymin])\n",
        "        new_xmax = np.min([image.shape[1], new_xmax])\n",
        "        new_ymax = np.min([image.shape[0], new_ymax])\n",
        "        stomata = image[new_ymin:new_ymax, new_xmin:new_xmax, :]\n",
        "        if stomata.shape != (CROP_SIZE, CROP_SIZE, 3):\n",
        "            daishi = np.zeros((CROP_SIZE, CROP_SIZE, 3), dtype=np.uint8)\n",
        "            daishi[0: stomata.shape[0], 0:stomata.shape[1], :] = stomata\n",
        "            stomata = daishi\n",
        "        else:\n",
        "            pass\n",
        "        stomatas.append(stomata)\n",
        "        offsets.append([new_xmin, new_ymin])\n",
        "    stomatas = np.array(stomatas)\n",
        "    offsets = np.array(offsets)\n",
        "    return stomatas, offsets"
      ],
      "metadata": {
        "id": "0EXSMmwTc77A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze(yolox, unet, folder, file):\n",
        "    _results = []\n",
        "    path = os.path.join(folder,file)\n",
        "    orig_image = cv2.imread(path)\n",
        "    image = orig_image.copy()\n",
        "    # detection requires BGR image\n",
        "    bboxes, scores, class_ids = yolox.inference(image)\n",
        "    orig_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = orig_image.copy()\n",
        "    # segmentation requires  RGB image\n",
        "    stomatas, offsets = crop_stomata(image, bboxes, 64)\n",
        "    \n",
        "    annotated1 = annotate(image, bboxes, scores, class_ids, conf=det_score_thresh, class_names=[\"open\", \"close\"],text=False)\n",
        "    annotated2 = annotated1.copy()\n",
        "    if len(bboxes) != 0:\n",
        "        for i, (stomata, bbox, score, class_id, offset) in enumerate(zip(stomatas, bboxes, scores, class_ids,offsets)):\n",
        "            if score < det_score_thresh:\n",
        "                continue\n",
        "            if class_id == 1:  # 0 open, 1 close\n",
        "                _results.append([folder, file,0,0,0])  # area, aperture, ratio\n",
        "                continue\n",
        "            else:\n",
        "                mask = unet.inference(stomata)\n",
        "                mask = mask > 0.5\n",
        "                lbl = label(mask)\n",
        "                props = regionprops(lbl)\n",
        "                if len(props):\n",
        "                    idx = np.argmax([x.area for x in props])\n",
        "                    prop = props[idx]\n",
        "                    area = prop.area\n",
        "                    try:\n",
        "                        ratio = prop.minor_axis_length / prop.major_axis_length\n",
        "                        width = prop.minor_axis_length\n",
        "                        length = prop.major_axis_length\n",
        "                    except Exception as e:\n",
        "                        ratio = np.nan\n",
        "                        width = np.nan\n",
        "                        length = np.nan\n",
        "                    mask = lbl == idx + 1\n",
        "                    contour = find_contours(mask)[0]\n",
        "                    contour = np.array([[y+offset[1],x+offset[0]] for y,x in contour])\n",
        "                    points = list(zip(contour[:,1],contour[:,0]))\n",
        "                    points = np.array(points).reshape((-1, 1, 2)).astype(np.int32)\n",
        "                    cv2.fillPoly(annotated2, pts=[points], color=(255,0,0))\n",
        "                    _results.append([folder, file,area,width,length,ratio])\n",
        "    return _results, orig_image, annotated1, annotated2"
      ],
      "metadata": {
        "id": "qavOiIZPpJyV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "NN4xhBdx6Ooo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want the detection to be more sensitive, change the det_score_thresh from 0.5 to ex. 0.1\n",
        "det_score_thresh = 0.5\n",
        "\n",
        "yolox = YoloxONNX(model_path=\"/content/221121_micro_yolox_s1920.onnx\",\n",
        "                  input_shape=(1920,1920), \n",
        "                  nms_th=0.45,\n",
        "                  score_th=det_score_thresh)\n",
        "unet = Segmentation(model_path=\"/content/221121_micro_seg.onnx\",\n",
        "                            input_shape=(64,64))"
      ],
      "metadata": {
        "id": "q1emn8P8dqdU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the path of the folder containing images you want to analyze in google folder\n",
        "# /content/gdrive/MyDrive is the path to the google drive top directory. change the FOLDERNAME to your foldername containing images\n",
        "folder = \"/content/gdrive/MyDrive/FOLDERNAME\"\n",
        "\n",
        "# change the EXT to other format in case you have a different extension image such as tiff or JPEG or .etc\n",
        "EXT = \".jpg\"\n",
        "\n",
        "# filter files that are only image files/\n",
        "files = os.listdir(folder)\n",
        "files = [x for x in files if x.endswith(EXT)]\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY0XBxo49EIq",
        "outputId": "ba1fb342-9a95-4828-8690-2b84e96b4c67"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20190507_Disk_Light_ABA_18.jpg\n",
            "20190507_Disk_Dark_DMSO_18.jpg\n",
            "20190507_Disk_Light_ABA_05.jpg\n",
            "20190507_Disk_Dark_DMSO_20.jpg\n",
            "20190507_Disk_Light_DMSO_10.jpg\n",
            "20190507_Disk_Light_DMSO_05.jpg\n",
            "20190507_Disk_Dark_FC_09.jpg\n",
            "20190507_Disk_Dark_FC_11.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if the above code does not output the filename of the images you want to anlayze, something is wrong. double check before proceeding"
      ],
      "metadata": {
        "id": "x1vfehgn_NqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
        "\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "out_folder = os.path.join(\"/content\",timestr)\n",
        "\n",
        "isExist = os.path.exists(out_folder)\n",
        "if not isExist:\n",
        "   os.makedirs(out_folder)\n",
        "\n",
        "print(\"Result Saving in\", out_folder)\n",
        "\n",
        "results = []\n",
        "for file in tqdm(files):\n",
        "    _results, image, annotated1, annotated2 = analyze(yolox,unet,folder,file)\n",
        "    results.extend(_results)\n",
        "    plt.figure(figsize=(45,15))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(annotated1)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(annotated2)\n",
        "    plt.savefig(os.path.join(out_folder,file))\n",
        "    plt.close()\n",
        "df = pd.DataFrame(results, columns=[\"folder\",\"file\",\"area\",\"width\",\"length\",\"ratio\"])\n",
        "df.to_csv(os.path.join(out_folder,\"result.csv\"),header=True)\n",
        "!zip -r -j {timestr+\".zip\"} {out_folder}\n",
        "print(\"zip file saved to\",timestr,\".zip\",\"right click and download at the left navigation\")"
      ],
      "metadata": {
        "id": "TaQXffVhgc8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b8a117-423a-47fc-b4b2-44d3c8ebe8d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result Saving in /content/20230107-024337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:17<00:00,  2.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: 20190507_Disk_Dark_FC_09.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Light_ABA_05.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Dark_DMSO_20.jpg (deflated 4%)\n",
            "  adding: result.csv (deflated 86%)\n",
            "  adding: 20190507_Disk_Light_DMSO_10.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Dark_DMSO_18.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Dark_FC_11.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Light_ABA_18.jpg (deflated 4%)\n",
            "  adding: 20190507_Disk_Light_DMSO_05.jpg (deflated 4%)\n",
            "zip file saved to 20230107-024337 .zip right click and download at the left navigation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcNEPJ-_jzwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group = df.groupby([\"folder\",\"file\"])\n",
        "print(\"mean\")\n",
        "print(group.mean())\n",
        "print(\"___\")\n",
        "print(\"std\")\n",
        "print(group.std())"
      ],
      "metadata": {
        "id": "bviNNSXw3fB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "palette = sns.color_palette([ '#F5AF98','#8CC1FF',], desat=1)\n",
        "sns.set_palette(palette)\n",
        "sns.boxplot(data=df, x=\"file\",y=\"width\", hue=\"folder\", showfliers=False, palette=palette)\n",
        "sns.stripplot(data=df,x=\"file\",y=\"width\", hue=\"folder\", dodge=True, jitter=True, size=4, color='black', alpha=0.4)\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "#l = plt.legend(handles[0:3], labels[0:3], bbox_to_anchor=(0,1), loc='upper left', borderaxespad=1)\n",
        "l = plt.legend(handles[0:2], labels[0:2], bbox_to_anchor=(0,1), loc='upper left', borderaxespad=1)\n",
        "\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "id": "0wsKIjF9lxBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyQsJs-ml7jD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}