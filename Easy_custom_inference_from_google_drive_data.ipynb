{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+6C+MdhHOa2pZ6mxJk1uP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phytometrics/arabidopsis_leaf_stomata_quantification/blob/main/Easy_custom_inference_from_google_drive_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "-M9eikfOaFPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "8_g5lVlgcoAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage.measure import label, regionprops, find_contours\n",
        "import onnxruntime\n",
        "import gdown\n",
        "import copy\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mHZmHn2xcNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get model weights and test data"
      ],
      "metadata": {
        "id": "opq7gB3ZaCA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpmX6eH0a9vQ"
      },
      "outputs": [],
      "source": [
        "det = \"1HjZJzRjs5NXlXchbRqOGybdSXx--HZNF\"\n",
        "seg = \"1Hhr68lZsycMmFkQlZ7WphK6cru29oZgN\"\n",
        "test_data_wom = \"1Hhh6HqrT9OxZRA_Q-feGbjE7Th6sIrlO\"\n",
        "test_data_wm = \"1HtzNRTl_5L9bBkW3QMU8yvuMuYUBXdOr\"\n",
        "!gdown {det}\n",
        "!gdown {seg}\n",
        "!gdown {test_data_wom}\n",
        "!gdown {test_data_wm}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -j /content/test_images_w_mask.zip -d /content/with_mask\n",
        "files = os.listdir(\"with_mask\")\n",
        "garbages = [os.path.join(\"with_mask\",x) for x in files if x.endswith(\".DS_Store\") or x.startswith(\".\")]\n",
        "for garbage in garbages:\n",
        "    os.remove(garbage)\n",
        "\n",
        "!unzip -j /content/test_images_wo_mask.zip -d /content/without_mask\n",
        "files = os.listdir(\"without_mask\")\n",
        "garbages = [os.path.join(\"without_mask\",x) for x in files if x.endswith(\".DS_Store\") or x.startswith(\".\")]\n",
        "for garbage in garbages:\n",
        "    os.remove(garbage)"
      ],
      "metadata": {
        "id": "pzQFjGgJd61j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n"
      ],
      "metadata": {
        "id": "O8pywCiZaMlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the codes in this cell are adopted/customized based on the following sites. Authors do not claim any rights regarding this code cell\n",
        "# https://github.com/Kazuhito00/YOLOX-ONNX-TFLite-Sample\n",
        "# https://github.com/Megvii-BaseDetection/YOLOX/blob/main/yolox/utils/visualize.py\n",
        "# both of the original repository are licenced with APACHE LICENSE 2.0\n",
        "\n",
        "class YoloxONNX(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path=\"\",\n",
        "        input_shape=(1920, 1920),\n",
        "        nms_th=0.45,\n",
        "        score_th=0.1,\n",
        "        with_p6=False,\n",
        "        providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],\n",
        "    ):\n",
        "        self.input_shape = input_shape\n",
        "        self.model_path = model_path\n",
        "        self.nms_th = nms_th\n",
        "        self.score_th = score_th\n",
        "        self.with_p6 = with_p6\n",
        "        self.onnx_session = onnxruntime.InferenceSession(\n",
        "            self.model_path,\n",
        "            providers=[providers[0]],\n",
        "        )\n",
        "\n",
        "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
        "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
        "\n",
        "    def inference(self, image):\n",
        "        temp_image = copy.deepcopy(image)\n",
        "        image_height, image_width = image.shape[0], image.shape[1]\n",
        "        image, ratio = self._preprocess(temp_image, self.input_shape)\n",
        "        results = self.onnx_session.run(\n",
        "            None,\n",
        "            {self.input_name: image[None, :, :, :]},\n",
        "        )\n",
        "        bboxes, scores, class_ids = self._postprocess(\n",
        "            results[0],\n",
        "            self.input_shape,\n",
        "            ratio,\n",
        "            self.nms_th,\n",
        "            self.score_th,\n",
        "            image_width,\n",
        "            image_height,\n",
        "            p6=self.with_p6,\n",
        "        )\n",
        "\n",
        "        return bboxes, scores, class_ids\n",
        "\n",
        "    def _preprocess(self, image, input_size, swap=(2, 0, 1)):\n",
        "        if len(image.shape) == 3:\n",
        "            padded_image = np.ones(\n",
        "                (input_size[0], input_size[1], 3), dtype=np.uint8) * 114\n",
        "        else:\n",
        "            padded_image = np.ones(input_size, dtype=np.uint8) * 114\n",
        "\n",
        "        ratio = min(input_size[0] / image.shape[0],\n",
        "                    input_size[1] / image.shape[1])\n",
        "        resized_image = cv2.resize(\n",
        "            image,\n",
        "            (int(image.shape[1] * ratio), int(image.shape[0] * ratio)),\n",
        "            interpolation=cv2.INTER_LINEAR,\n",
        "        )\n",
        "        resized_image = resized_image.astype(np.uint8)\n",
        "\n",
        "        padded_image[:int(image.shape[0] * ratio), :int(image.shape[1] *\n",
        "                                                        ratio)] = resized_image\n",
        "        padded_image = padded_image.transpose(swap)\n",
        "        padded_image = np.ascontiguousarray(padded_image, dtype=np.float32)\n",
        "\n",
        "        return padded_image, ratio\n",
        "\n",
        "    def _postprocess(\n",
        "        self,\n",
        "        outputs,\n",
        "        img_size,\n",
        "        ratio,\n",
        "        nms_th,\n",
        "        score_th,\n",
        "        max_width,\n",
        "        max_height,\n",
        "        p6=False,\n",
        "    ):\n",
        "        grids = []\n",
        "        expanded_strides = []\n",
        "\n",
        "        if not p6:\n",
        "            strides = [8, 16, 32]\n",
        "        else:\n",
        "            strides = [8, 16, 32, 64]\n",
        "\n",
        "        hsizes = [img_size[0] // stride for stride in strides]\n",
        "        wsizes = [img_size[1] // stride for stride in strides]\n",
        "\n",
        "        for hsize, wsize, stride in zip(hsizes, wsizes, strides):\n",
        "            xv, yv = np.meshgrid(np.arange(wsize), np.arange(hsize))\n",
        "            grid = np.stack((xv, yv), 2).reshape(1, -1, 2)\n",
        "            grids.append(grid)\n",
        "            shape = grid.shape[:2]\n",
        "            expanded_strides.append(np.full((*shape, 1), stride))\n",
        "\n",
        "        grids = np.concatenate(grids, 1)\n",
        "        expanded_strides = np.concatenate(expanded_strides, 1)\n",
        "        outputs[..., :2] = (outputs[..., :2] + grids) * expanded_strides\n",
        "        outputs[..., 2:4] = np.exp(outputs[..., 2:4]) * expanded_strides\n",
        "\n",
        "        predictions = outputs[0]\n",
        "        boxes = predictions[:, :4]\n",
        "        scores = predictions[:, 4:5] * predictions[:, 5:]\n",
        "\n",
        "        boxes_xyxy = np.ones_like(boxes)\n",
        "        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2.\n",
        "        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2.\n",
        "        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2.\n",
        "        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2.\n",
        "        boxes_xyxy /= ratio\n",
        "\n",
        "        dets = self._multiclass_nms(\n",
        "            boxes_xyxy,\n",
        "            scores,\n",
        "            nms_thr=nms_th,\n",
        "            score_thr=score_th,\n",
        "        )\n",
        "\n",
        "        bboxes, scores, class_ids = [], [], []\n",
        "        if dets is not None:\n",
        "            bboxes, scores, class_ids = dets[:, :4], dets[:, 4], dets[:, 5]\n",
        "            for bbox in bboxes:\n",
        "                bbox[0] = max(0, bbox[0])\n",
        "                bbox[1] = max(0, bbox[1])\n",
        "                bbox[2] = min(bbox[2], max_width)\n",
        "                bbox[3] = min(bbox[3], max_height)\n",
        "\n",
        "        return bboxes, scores, class_ids\n",
        "\n",
        "    def _nms(self, boxes, scores, nms_thr):\n",
        "        x1 = boxes[:, 0]\n",
        "        y1 = boxes[:, 1]\n",
        "        x2 = boxes[:, 2]\n",
        "        y2 = boxes[:, 3]\n",
        "\n",
        "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "        order = scores.argsort()[::-1]\n",
        "\n",
        "        keep = []\n",
        "        while order.size > 0:\n",
        "            i = order[0]\n",
        "            keep.append(i)\n",
        "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "            inter = w * h\n",
        "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "\n",
        "            inds = np.where(ovr <= nms_thr)[0]\n",
        "            order = order[inds + 1]\n",
        "\n",
        "        return keep\n",
        "\n",
        "    def _multiclass_nms(\n",
        "        self,\n",
        "        boxes,\n",
        "        scores,\n",
        "        nms_thr,\n",
        "        score_thr,\n",
        "        class_agnostic=True,\n",
        "    ):\n",
        "        if class_agnostic:\n",
        "            nms_method = self._multiclass_nms_class_agnostic\n",
        "        else:\n",
        "            nms_method = self._multiclass_nms_class_aware\n",
        "\n",
        "        return nms_method(boxes, scores, nms_thr, score_thr)\n",
        "\n",
        "    def _multiclass_nms_class_aware(self, boxes, scores, nms_thr, score_thr):\n",
        "        final_dets = []\n",
        "        num_classes = scores.shape[1]\n",
        "\n",
        "        for cls_ind in range(num_classes):\n",
        "            cls_scores = scores[:, cls_ind]\n",
        "            valid_score_mask = cls_scores > score_thr\n",
        "\n",
        "            if valid_score_mask.sum() == 0:\n",
        "                continue\n",
        "            else:\n",
        "                valid_scores = cls_scores[valid_score_mask]\n",
        "                valid_boxes = boxes[valid_score_mask]\n",
        "                keep = self._nms(valid_boxes, valid_scores, nms_thr)\n",
        "                if len(keep) > 0:\n",
        "                    cls_inds = np.ones((len(keep), 1)) * cls_ind\n",
        "                    dets = np.concatenate(\n",
        "                        [\n",
        "                            valid_boxes[keep], valid_scores[keep, None],\n",
        "                            cls_inds\n",
        "                        ],\n",
        "                        1,\n",
        "                    )\n",
        "                    final_dets.append(dets)\n",
        "\n",
        "        if len(final_dets) == 0:\n",
        "            return None\n",
        "\n",
        "        return np.concatenate(final_dets, 0)\n",
        "\n",
        "    def _multiclass_nms_class_agnostic(self, boxes, scores, nms_thr,\n",
        "                                       score_thr):\n",
        "        cls_inds = scores.argmax(1)\n",
        "        cls_scores = scores[np.arange(len(cls_inds)), cls_inds]\n",
        "\n",
        "        valid_score_mask = cls_scores > score_thr\n",
        "\n",
        "        if valid_score_mask.sum() == 0:\n",
        "            return None\n",
        "\n",
        "        valid_scores = cls_scores[valid_score_mask]\n",
        "        valid_boxes = boxes[valid_score_mask]\n",
        "        valid_cls_inds = cls_inds[valid_score_mask]\n",
        "        keep = self._nms(valid_boxes, valid_scores, nms_thr)\n",
        "\n",
        "        dets = None\n",
        "        if keep:\n",
        "            dets = np.concatenate([\n",
        "                valid_boxes[keep],\n",
        "                valid_scores[keep, None],\n",
        "                valid_cls_inds[keep, None],\n",
        "            ], 1)\n",
        "\n",
        "        return dets\n",
        "def annotate(img, boxes, scores, cls_ids, conf=0.5, class_names=None, text=True, CROP_SIZE=64):\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        cls_id = int(cls_ids[i])\n",
        "        score = scores[i]\n",
        "        if score < conf:\n",
        "            continue\n",
        "        x0 = int(box[0])\n",
        "        y0 = int(box[1])\n",
        "        x1 = int(box[2])\n",
        "        y1 = int(box[3])\n",
        "\n",
        "        xmin, ymin, xmax, ymax = x0, y0, x1, y1\n",
        "        xcenter = int((xmin + xmax) / 2)\n",
        "        ycenter = int((ymin + ymax) / 2)\n",
        "        new_xmin = xcenter - CROP_SIZE // 2\n",
        "        new_ymin = ycenter - CROP_SIZE // 2\n",
        "        new_xmax = xcenter + CROP_SIZE // 2\n",
        "        new_ymax = ycenter + CROP_SIZE // 2\n",
        "        new_xmin = np.max([0, new_xmin]) \n",
        "        new_ymin = np.max([0, new_ymin])\n",
        "        new_xmax = np.min([img.shape[1], new_xmax])\n",
        "        new_ymax = np.min([img.shape[0], new_ymax])\n",
        "\n",
        "        x0, y0, x1, y1 = new_xmin, new_ymin, new_xmax, new_ymax\n",
        "\n",
        "        color = (_COLORS[cls_id] * 255).astype(np.uint8).tolist()\n",
        "        text = '{}:{:.1f}%'.format(class_names[cls_id], score * 100)\n",
        "        txt_color = (0, 0, 0) if np.mean(_COLORS[cls_id]) > 0.5 else (255, 255, 255)\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        txt_size = cv2.getTextSize(text, font, 0.4, 1)[0]\n",
        "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
        "\n",
        "        txt_bk_color = (_COLORS[cls_id] * 255 * 0.7).astype(np.uint8).tolist()\n",
        "        if text:\n",
        "            cv2.rectangle(\n",
        "                img,\n",
        "                (x0, y0 + 1),\n",
        "                (x0 + txt_size[0] + 1, y0 + int(1.5*txt_size[1])),\n",
        "                txt_bk_color,\n",
        "                -1\n",
        "            )\n",
        "            cv2.putText(img, text, (x0, y0 + txt_size[1]), font, 0.4, txt_color, thickness=1)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "_COLORS = np.array(\n",
        "    [\n",
        "        1., 0., 0., # open red\n",
        "        0., 0., 1., # close blue\n",
        "        # R, G, B\n",
        "    ]\n",
        ").astype(np.float32).reshape(-1, 3)"
      ],
      "metadata": {
        "id": "ZQciEEgNcUkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Segmentation(object):\n",
        "    def __init__(self,\n",
        "                 model_path=\"\",\n",
        "                 input_shape=(64, 64),\n",
        "                 providers=['CPUExecutionProvider'],\n",
        "                 ):\n",
        "        self.input_shape = input_shape\n",
        "        self.onnx_session = onnxruntime.InferenceSession(\n",
        "            model_path,\n",
        "            providers=providers,\n",
        "        )\n",
        "\n",
        "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
        "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
        "\n",
        "    def inference(self, image):\n",
        "        image = image.transpose((2, 0, 1)).astype(\"float32\")\n",
        "        result = self.onnx_session.run(\n",
        "            None,\n",
        "            {self.input_name: image[None, :, :, :]},\n",
        "        )[0][0][0]\n",
        "        return result\n",
        "\n",
        "\n",
        "def crop_stomata(image, dets, CROP_SIZE):\n",
        "    stomatas = []\n",
        "    offsets = []\n",
        "\n",
        "    for det in dets:\n",
        "        xmin, ymin, xmax, ymax = det[0], det[1], det[2], det[3]\n",
        "        xcenter = int((xmin + xmax) / 2)\n",
        "        ycenter = int((ymin + ymax) / 2)\n",
        "        new_xmin = xcenter - CROP_SIZE // 2\n",
        "        new_ymin = ycenter - CROP_SIZE // 2\n",
        "        new_xmax = xcenter + CROP_SIZE // 2\n",
        "        new_ymax = ycenter + CROP_SIZE // 2\n",
        "        new_xmin = np.max([0, new_xmin])\n",
        "        new_ymin = np.max([0, new_ymin])\n",
        "        new_xmax = np.min([image.shape[1], new_xmax])\n",
        "        new_ymax = np.min([image.shape[0], new_ymax])\n",
        "        stomata = image[new_ymin:new_ymax, new_xmin:new_xmax, :]\n",
        "        if stomata.shape != (CROP_SIZE, CROP_SIZE, 3):\n",
        "            daishi = np.zeros((CROP_SIZE, CROP_SIZE, 3), dtype=np.uint8)\n",
        "            daishi[0: stomata.shape[0], 0:stomata.shape[1], :] = stomata\n",
        "            stomata = daishi\n",
        "        else:\n",
        "            pass\n",
        "        stomatas.append(stomata)\n",
        "        offsets.append([new_xmin, new_ymin])\n",
        "    stomatas = np.array(stomatas)\n",
        "    offsets = np.array(offsets)\n",
        "    return stomatas, offsets"
      ],
      "metadata": {
        "id": "0EXSMmwTc77A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze(yolox, unet, folder, file):\n",
        "    _results = []\n",
        "    path = os.path.join(folder,file)\n",
        "    orig_image = cv2.imread(path)\n",
        "    image = orig_image.copy()\n",
        "    # detection requires BGR image\n",
        "    bboxes, scores, class_ids = yolox.inference(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # segmentation requires  RGB image\n",
        "    stomatas, offsets = crop_stomata(image, bboxes, 64)\n",
        "    \n",
        "    annotated = annotate(image, bboxes, scores, class_ids, conf=det_score_thresh, class_names=[\"open\", \"close\"],text=False)\n",
        "    if len(bboxes) != 0:\n",
        "        for i, (stomata, bbox, score, class_id, offset) in enumerate(zip(stomatas, bboxes, scores, class_ids,offsets)):\n",
        "            if score < det_score_thresh:\n",
        "                continue\n",
        "            if class_id == 1:  # 0 open, 1 close\n",
        "                _results.append([folder, file,0,0,0])  # area, aperture, ratio\n",
        "                continue\n",
        "            else:\n",
        "                mask = unet.inference(stomata)\n",
        "                mask = mask > 0.5\n",
        "                lbl = label(mask)\n",
        "                props = regionprops(lbl)\n",
        "                if len(props):\n",
        "                    idx = np.argmax([x.area for x in props])\n",
        "                    prop = props[idx]\n",
        "                    area = prop.area\n",
        "                    try:\n",
        "                        ratio = prop.minor_axis_length / prop.major_axis_length\n",
        "                        width = prop.minor_axis_length*scale\n",
        "                        length = prop.major_axis_length*scale\n",
        "                    except Exception as e:\n",
        "                        ratio = np.nan\n",
        "                        width = np.nan\n",
        "                        length = np.nan\n",
        "                    mask = lbl == idx + 1\n",
        "                    contour = find_contours(mask)[0]\n",
        "                    contour = np.array([[y+offset[1],x+offset[0]] for y,x in contour])\n",
        "                    points = list(zip(contour[:,1],contour[:,0]))\n",
        "                    points = np.array(points).reshape((-1, 1, 2)).astype(np.int32)\n",
        "                    cv2.fillPoly(annotated, pts=[points], color=(255,0,0))\n",
        "                    _results.append([folder, file,area,width,length,ratio])\n",
        "    return _results, annotated"
      ],
      "metadata": {
        "id": "qavOiIZPpJyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "det_score_thresh = 0.5\n",
        "yolox = YoloxONNX(model_path=\"/content/221121_micro_yolox_s1920.onnx\",\n",
        "                  input_shape=(1920,1920), \n",
        "                  nms_th=0.45,\n",
        "                  score_th=det_score_thresh)\n",
        "unet = Segmentation(model_path=\"/content/221121_micro_seg.onnx\",\n",
        "                            input_shape=(64,64))"
      ],
      "metadata": {
        "id": "q1emn8P8dqdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_score_thresh = 0.5\n",
        "scale = 0.345  # scale for px to um conversion in testimage\n",
        "results = []\n",
        "\n",
        "folder = \"without_mask\"\n",
        "files = os.listdir(folder)\n",
        "\n",
        "for file in tqdm(files):\n",
        "    _results, annotated = analyze(yolox,unet,folder,file)\n",
        "    results.extend(_results)\n",
        "    plt.imshow(annotated)\n",
        "    plt.show()\n",
        "\n",
        "folder = \"with_mask\"\n",
        "files = os.listdir(folder)\n",
        "\n",
        "for file in tqdm(files):\n",
        "    _results, annotated = analyze(yolox,unet,folder,file)\n",
        "    results.extend(_results)\n",
        "    plt.imshow(annotated)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TaQXffVhgc8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results, columns=[\"folder\",\"file\",\"area\",\"width\",\"length\",\"ratio\"])\n",
        "df"
      ],
      "metadata": {
        "id": "xcNEPJ-_jzwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group = df.groupby([\"folder\",\"file\"])\n",
        "print(\"mean\")\n",
        "print(group.mean())\n",
        "print(\"___\")\n",
        "print(\"std\")\n",
        "print(group.std())"
      ],
      "metadata": {
        "id": "bviNNSXw3fB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "palette = sns.color_palette([ '#F5AF98','#8CC1FF',], desat=1)\n",
        "sns.set_palette(palette)\n",
        "sns.boxplot(data=df, x=\"file\",y=\"width\", hue=\"folder\", showfliers=False, palette=palette)\n",
        "sns.stripplot(data=df,x=\"file\",y=\"width\", hue=\"folder\", dodge=True, jitter=True, size=4, color='black', alpha=0.4)\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "#l = plt.legend(handles[0:3], labels[0:3], bbox_to_anchor=(0,1), loc='upper left', borderaxespad=1)\n",
        "l = plt.legend(handles[0:2], labels[0:2], bbox_to_anchor=(0,1), loc='upper left', borderaxespad=1)\n",
        "\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "id": "0wsKIjF9lxBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyQsJs-ml7jD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}